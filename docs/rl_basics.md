# RL basics used in this project

- Agent learns by interacting with environment in episodes.
- DQN: off-policy Q-learning with neural network function approximator.
- Replay buffer stores experiences to break correlation between samples.
- Target network stabilizes learning by slow updates.
